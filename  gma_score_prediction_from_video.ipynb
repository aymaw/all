{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyNnw1XEEck0vR6XnKEcQc5t",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/aymaw/all/blob/main/%20gma_score_prediction_from_video.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Part A"
      ],
      "metadata": {
        "id": "9uoBKjiCnKIA"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "UuYHmM8tm7mp"
      },
      "outputs": [],
      "source": [
        "# Mount Google Drive and create directories\n",
        "from google.colab import drive\n",
        "import os\n",
        "from IPython.display import Video\n",
        "\n",
        "drive.mount('/content/drive')\n",
        "\n",
        "video_dir = \"/content/drive/MyDrive/mypose_videos\"\n",
        "output_dir = \"/content/drive/MyDrive/mypose_outputs\"\n",
        "os.makedirs(video_dir, exist_ok=True)\n",
        "os.makedirs(output_dir, exist_ok=True)\n",
        "\n",
        "# Install Dependencies\n",
        "!sudo apt update\n",
        "!sudo apt install python3.8-full python3-pip -y\n",
        "!sudo update-alternatives --install /usr/bin/python3 python3 /usr/bin/python3.8 1\n",
        "\n",
        "!pip install openmim gdown ipykernel\n",
        "!pip install torch torchvision torchaudio --index-url https://download.pytorch.org/whl/cu121\n",
        "!mim install mmengine\n",
        "!pip install mmcv==2.1.0 -f https://download.openmmlab.com/mmcv/dist/cu121/torch2.1/index.html\n",
        "!mim install \"mmpose>=1.1.0\"\n",
        "\n",
        "!git clone https://github.com/open-mmlab/mmpose.git\n",
        "%cd mmpose\n",
        "!pip install -r requirements.txt\n",
        "!pip install -v -e .\n",
        "\n",
        "# Select Models for Testing\n",
        "models = ['vitpose-h', 'hrnet-w48', 'resnet50', 'openpose']\n",
        "\n",
        "# Test 4 Models\n",
        "for model in models:\n",
        "    print(f\"Testing model: {model}\")\n",
        "    for video_file in os.listdir(video_dir):\n",
        "        video_path = os.path.join(video_dir, video_file)\n",
        "        vis_output = f\"{output_dir}/{model}_{video_file.split('.')[0]}_vis.mp4\"\n",
        "        pred_output = f\"{output_dir}/{model}_{video_file.split('.')[0]}_pred.json\"\n",
        "\n",
        "        !python ./demo/inferencer_demo.py {video_path} \\\n",
        "            --pose2d {model} --pred-out-dir {pred_output} \\\n",
        "            --vis-out-dir {vis_output} --skeleton-style openpose \\\n",
        "            --radius 5 --thickness 3\n",
        "\n",
        "        # Display video output\n",
        "        display(Video(vis_output))"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Part B"
      ],
      "metadata": {
        "id": "5h2ZbPyCrEHB"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Import required libraries\n",
        "import os\n",
        "import sys\n",
        "import json\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "from tqdm import tqdm\n",
        "\n",
        "# Step 1: Ensure the utility files are downloaded and accessible\n",
        "# Download necessary files if they don't already exist\n",
        "utility_files = {\n",
        "    \"kinematics.py\": \"https://raw.githubusercontent.com/quietscientist/gma_score_prediction_from_video/main/utils/kinematics.py\",\n",
        "    \"processing.py\": \"https://raw.githubusercontent.com/quietscientist/gma_score_prediction_from_video/main/utils/processing.py\",\n",
        "    \"skeleton.py\": \"https://raw.githubusercontent.com/quietscientist/gma_score_prediction_from_video/main/utils/skeleton.py\",\n",
        "    \"circstat.py\": \"https://raw.githubusercontent.com/quietscientist/gma_score_prediction_from_video/main/utils/circstat.py\",\n",
        "}\n",
        "\n",
        "for filename, url in utility_files.items():\n",
        "    if not os.path.exists(filename):\n",
        "        print(f\"Downloading {filename}...\")\n",
        "        !wget -q -O {filename} {url}\n",
        "    else:\n",
        "        print(f\"{filename} already exists, skipping download.\")\n",
        "\n",
        "# Step 2: Update the system path to include the current directory\n",
        "sys.path.append(os.getcwd())\n",
        "\n",
        "# Step 3: Import utility functions\n",
        "try:\n",
        "    from kinematics import compute_displacement_velocity, compute_angles\n",
        "    from processing import interpolate_data, smooth_data\n",
        "    from skeleton import normalize_skeleton\n",
        "    import circstat as CS\n",
        "except ModuleNotFoundError as e:\n",
        "    print(\"Error importing utility files. Ensure all files are downloaded and paths are set correctly.\")\n",
        "    raise e\n",
        "\n",
        "# Step 4: Define paths\n",
        "video_dir = \"/content/drive/MyDrive/mypose_videos\"  # Update with your video folder path\n",
        "output_dir = \"/content/drive/MyDrive/mypose_outputs\"  # Update with your desired output folder path\n",
        "os.makedirs(output_dir, exist_ok=True)\n",
        "\n",
        "# Step 5: Load videos and process data\n",
        "# Example: Process pose data from videos in `video_dir` and save outputs in `output_dir`\n",
        "def process_videos(video_dir, output_dir):\n",
        "    # List all videos in the directory\n",
        "    video_files = [f for f in os.listdir(video_dir) if f.endswith(('.mp4', '.avi'))]\n",
        "\n",
        "    for video_file in tqdm(video_files, desc=\"Processing Videos\"):\n",
        "        video_path = os.path.join(video_dir, video_file)\n",
        "        output_path = os.path.join(output_dir, os.path.splitext(video_file)[0] + \"_features.json\")\n",
        "\n",
        "        try:\n",
        "            # Simulate loading video data and processing it\n",
        "            print(f\"Processing video: {video_file}\")\n",
        "\n",
        "            # Placeholder for actual pose extraction (replace with real implementation)\n",
        "            # Example: Call pose extraction model\n",
        "            skeleton_data = extract_pose_data(video_path)  # Replace with your pose extraction function\n",
        "\n",
        "            # Normalize the skeleton\n",
        "            normalized_skeleton = normalize_skeleton(skeleton_data)\n",
        "\n",
        "            # Interpolate and smooth the skeleton data\n",
        "            interpolated_skeleton = interpolate_data(normalized_skeleton)\n",
        "            smoothed_skeleton = smooth_data(interpolated_skeleton)\n",
        "\n",
        "            # Compute displacement velocity and angles\n",
        "            displacement_velocity = compute_displacement_velocity(smoothed_skeleton)\n",
        "            joint_angles = compute_angles(smoothed_skeleton)\n",
        "\n",
        "            # Combine features into a dictionary\n",
        "            features = {\n",
        "                \"displacement_velocity\": displacement_velocity,\n",
        "                \"joint_angles\": joint_angles,\n",
        "            }\n",
        "\n",
        "            # Save features to a JSON file\n",
        "            with open(output_path, \"w\") as json_file:\n",
        "                json.dump(features, json_file, indent=4)\n",
        "            print(f\"Features saved to {output_path}\")\n",
        "\n",
        "        except Exception as e:\n",
        "            print(f\"Error processing video {video_file}: {e}\")\n",
        "\n",
        "# Placeholder for pose extraction function\n",
        "def extract_pose_data(video_path):\n",
        "    \"\"\"\n",
        "    Simulates pose extraction from a video file.\n",
        "    Replace with your actual pose extraction function or library call.\n",
        "    \"\"\"\n",
        "    # TODO: Add actual implementation\n",
        "    print(f\"Extracting pose data from {video_path}...\")\n",
        "    return [{\"x\": 0, \"y\": 0}]  # Dummy skeleton data\n",
        "\n",
        "# Run the processing pipeline\n",
        "process_videos(video_dir, output_dir)\n"
      ],
      "metadata": {
        "id": "EPXEa4fgrGtJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Part C"
      ],
      "metadata": {
        "id": "TqUcEliYrHM8"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Install Necessary Libraries (uncomment if running for the first time)\n",
        "# !pip install --upgrade pip setuptools wheel\n",
        "# !apt-get install swig build-essential libssl-dev libffi-dev python3-dev\n",
        "# !pip install auto-sklearn\n",
        "\n",
        "# Import Required Libraries\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "from autosklearn.classification import AutoSklearnClassifier\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import accuracy_score, classification_report, roc_auc_score\n",
        "import json\n",
        "\n",
        "# Step 1: Load the Pose Data\n",
        "pose_data_path = \"/content/drive/MyDrive/pose_data.json\"\n",
        "\n",
        "# Loading a JSON file with pose data\n",
        "with open(pose_data_path, 'r') as file:\n",
        "    pose_data = json.load(file)\n",
        "\n",
        "# Convert JSON to DataFrame\n",
        "pose_df = pd.json_normalize(pose_data)\n",
        "print(f\"Loaded Data Shape: {pose_df.shape}\")\n",
        "print(pose_df.head())\n",
        "\n",
        "# Step 2: Preprocess Data\n",
        "# Drop non-numeric or irrelevant columns\n",
        "irrelevant_columns = ['frame_id', 'timestamp']\n",
        "pose_df = pose_df.drop(columns=irrelevant_columns, errors='ignore')\n",
        "\n",
        "# Handle missing values\n",
        "pose_df = pose_df.fillna(method='ffill').fillna(method='bfill')\n",
        "\n",
        "# Normalize numeric data\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "scaler = StandardScaler()\n",
        "pose_df.iloc[:, :] = scaler.fit_transform(pose_df.iloc[:, :])\n",
        "\n",
        "# Step 3: Split Data into Features (X) and Labels (y)\n",
        "X = pose_df.drop(columns=['label'], errors='ignore')\n",
        "y = pose_df['label']\n",
        "\n",
        "# Split into training and testing sets\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)\n",
        "\n",
        "# Step 4: Train Auto-Sklearn Classifier\n",
        "model = AutoSklearnClassifier(\n",
        "    time_left_for_this_task=300,  # Total time for model optimization in seconds\n",
        "    per_run_time_limit=30,       # Time limit for each model training\n",
        "    memory_limit=1024            # Memory limit in MB\n",
        ")\n",
        "\n",
        "print(\"Training AutoSklearnClassifier...\")\n",
        "model.fit(X_train, y_train)\n",
        "\n",
        "# Step 5: Evaluate the Model\n",
        "print(\"Evaluating the model...\")\n",
        "y_pred = model.predict(X_test)\n",
        "accuracy = accuracy_score(y_test, y_pred)\n",
        "roc_auc = roc_auc_score(y_test, model.predict_proba(X_test), multi_class=\"ovr\")\n",
        "\n",
        "print(f\"Accuracy: {accuracy}\")\n",
        "print(f\"ROC-AUC Score: {roc_auc}\")\n",
        "print(\"Classification Report:\")\n",
        "print(classification_report(y_test, y_pred))\n",
        "\n",
        "# Step 6: Save the Model (Optional)\n",
        "import joblib\n",
        "model_save_path = \"/content/auto_sklearn_model.pkl\"\n",
        "joblib.dump(model, model_save_path)\n",
        "print(f\"Model saved to {model_save_path}\")\n"
      ],
      "metadata": {
        "id": "x83iaG9BrHxc"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}